{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgSxIhEhKDTpLbKmWipP1w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JUANCHOLOCO/LanGrandTaller1/blob/main/colabLaboratorio1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación\n",
        "%%capture\n",
        "# Instalar paquetes necesarios (ejecutar en celda separada en Colab)\n",
        "!pip install -U langchain-google-genai langgraph langchain-core langchain-community python-dotenv"
      ],
      "metadata": {
        "id": "YyPvw_32umeV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Obtener API key de Google Colab Secrets\n",
        "try:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBODFU6gA-Bvt8LzqNcEooZ2HEmHkWZdpg\"\n",
        "  #GOOGLE_API_KEY = userdata.get('AIzaSyBODFU6gA-Bvt8LzqNcEooZ2HEmHkWZdpg')\n",
        "  print(\"API Key de Gemini cargada correctamente\")\n",
        "except Exception as e:\n",
        "  print(\"Error al cargar API Key. Configura en: Runtime > Manage secrets\")\n",
        "  print(\"Nombre del secreto: GOOGLE_API_KEY\")\n",
        "  raise e\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGYA7sumuq3F",
        "outputId": "9b654082-5037-497e-b499-35d9329466fa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key de Gemini cargada correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key='AIzaSyBODFU6gA-Bvt8LzqNcEooZ2HEmHkWZdpg')\n",
        "models = list_models()\n",
        "print(\"Modelos disponibles:\")\n",
        "for model in models:\n",
        "  print(f\"- {model.name} | Métodos soportados: {model.supported_generation_methods}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "gnooZ6G-wDou",
        "outputId": "fd5c8925-6b09-43a7-d1e2-1f8e30eada70"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelos disponibles:\n",
            "- models/embedding-gecko-001 | Métodos soportados: ['embedText', 'countTextTokens']\n",
            "- models/gemini-2.5-flash | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.5-pro | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.0-flash-exp | Métodos soportados: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "- models/gemini-2.0-flash | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.0-flash-001 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.0-flash-exp-image-generation | Métodos soportados: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "- models/gemini-2.0-flash-lite-001 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.0-flash-lite | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.0-flash-lite-preview-02-05 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.0-flash-lite-preview | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-exp-1206 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.5-flash-preview-tts | Métodos soportados: ['countTokens', 'generateContent']\n",
            "- models/gemini-2.5-pro-preview-tts | Métodos soportados: ['countTokens', 'generateContent']\n",
            "- models/gemma-3-1b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "- models/gemma-3-4b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "- models/gemma-3-12b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "- models/gemma-3-27b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "- models/gemma-3n-e4b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "- models/gemma-3n-e2b-it | Métodos soportados: ['generateContent', 'countTokens']\n",
            "- models/gemini-flash-latest | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-flash-lite-latest | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-pro-latest | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.5-flash-lite | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.5-flash-image-preview | Métodos soportados: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "- models/gemini-2.5-flash-image | Métodos soportados: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "- models/gemini-2.5-flash-preview-09-2025 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-2.5-flash-lite-preview-09-2025 | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-3-pro-preview | Métodos soportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "- models/gemini-3-pro-image-preview | Métodos soportados: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "- models/nano-banana-pro-preview | Métodos soportados: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "- models/gemini-robotics-er-1.5-preview | Métodos soportados: ['generateContent', 'countTokens']\n",
            "- models/gemini-2.5-computer-use-preview-10-2025 | Métodos soportados: ['generateContent', 'countTokens']\n",
            "- models/embedding-001 | Métodos soportados: ['embedContent']\n",
            "- models/text-embedding-004 | Métodos soportados: ['embedContent']\n",
            "- models/gemini-embedding-exp-03-07 | Métodos soportados: ['embedContent', 'countTextTokens', 'countTokens']\n",
            "- models/gemini-embedding-exp | Métodos soportados: ['embedContent', 'countTextTokens', 'countTokens']\n",
            "- models/gemini-embedding-001 | Métodos soportados: ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
            "- models/aqa | Métodos soportados: ['generateAnswer']\n",
            "- models/imagen-4.0-generate-preview-06-06 | Métodos soportados: ['predict']\n",
            "- models/imagen-4.0-ultra-generate-preview-06-06 | Métodos soportados: ['predict']\n",
            "- models/imagen-4.0-generate-001 | Métodos soportados: ['predict']\n",
            "- models/imagen-4.0-ultra-generate-001 | Métodos soportados: ['predict']\n",
            "- models/imagen-4.0-fast-generate-001 | Métodos soportados: ['predict']\n",
            "- models/veo-2.0-generate-001 | Métodos soportados: ['predictLongRunning']\n",
            "- models/veo-3.0-generate-001 | Métodos soportados: ['predictLongRunning']\n",
            "- models/veo-3.0-fast-generate-001 | Métodos soportados: ['predictLongRunning']\n",
            "- models/veo-3.1-generate-preview | Métodos soportados: ['predictLongRunning']\n",
            "- models/veo-3.1-fast-generate-preview | Métodos soportados: ['predictLongRunning']\n",
            "- models/gemini-2.0-flash-live-001 | Métodos soportados: ['bidiGenerateContent', 'countTokens']\n",
            "- models/gemini-live-2.5-flash-preview | Métodos soportados: ['bidiGenerateContent', 'countTokens']\n",
            "- models/gemini-2.5-flash-live-preview | Métodos soportados: ['bidiGenerateContent', 'countTokens']\n",
            "- models/gemini-2.5-flash-native-audio-latest | Métodos soportados: ['countTokens', 'bidiGenerateContent']\n",
            "- models/gemini-2.5-flash-native-audio-preview-09-2025 | Métodos soportados: ['countTokens', 'bidiGenerateContent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[Sequence[dict], operator.add]\n",
        "  current_step: str\n",
        "  analysis_results: dict"
      ],
      "metadata": {
        "id": "YiEgy5DNwwPe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=1000,\n",
        "    google_api_key=\"AIzaSyBODFU6gA-Bvt8LzqNcEooZ2HEmHkWZdpg\"\n",
        ")"
      ],
      "metadata": {
        "id": "oMTK6F3HxwKl"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_input_gemini(state: AgentState, llm_instance):\n",
        "    \"\"\"Nodo que analiza la entrada usando Gemini\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    gemini_messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Eres un analista experto. Analiza la solicitud del usuario y determina qué tipo de ayuda necesita.\"},\n",
        "        *messages\n",
        "    ]\n",
        "\n",
        "    response = llm_instance.invoke(gemini_messages)\n",
        "    print(f\" Análisis completado: {response.content[:100]}...\")  # Debug\n",
        "\n",
        "    return {\n",
        "        \"current_step\": \"analysis_complete\",\n",
        "        \"analysis_results\": {\n",
        "            \"intent\": \"technical_support\",\n",
        "            \"confidence\": 0.92,\n",
        "            \"details\": response.content\n",
        "        }\n",
        "    }\n",
        "\n",
        "def generate_response_gemini(state: AgentState, llm_instance):\n",
        "    \"\"\"Nodo que genera respuesta final con Gemini\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    analysis = state[\"analysis_results\"]\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "    Eres un asistente técnico experto. El análisis indica:\n",
        "    - Intención: {analysis['intent']}\n",
        "    - Confianza: {analysis['confidence']:.2f}\n",
        "    - Detalles: {analysis['details'][:200]}\n",
        "\n",
        "    Proporciona una respuesta clara, técnica y útil. Sé conciso pero completo.\n",
        "    \"\"\"\n",
        "\n",
        "    gemini_messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        *messages\n",
        "    ]\n",
        "\n",
        "    response = llm_instance.invoke(gemini_messages)\n",
        "    print(f\"Respuesta generada: {response.content[:100]}...\")  # Debug\n",
        "\n",
        "    return {\n",
        "        \"current_step\": \"response_generated\",\n",
        "        \"messages\": [{\"role\": \"assistant\", \"content\": response.content}]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "xvHvdmLf8aGu"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear wrappers para el grafo (MEJOR PRÁCTICA)\n",
        "def analyze_node(state):\n",
        "    return analyze_input_gemini(state, llm)\n",
        "\n",
        "def respond_node(state):\n",
        "    return generate_response_gemini(state, llm)"
      ],
      "metadata": {
        "id": "_w1iTfdk0RtV"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir el grafo\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"analyze\", analyze_node)\n",
        "workflow.add_node(\"respond\", respond_node)\n",
        "workflow.add_edge(START, \"analyze\")\n",
        "workflow.add_edge(\"analyze\", \"respond\")\n",
        "workflow.add_edge(\"respond\", END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT0RiIAU0U7s",
        "outputId": "90b10c40-77f6-4713-93d8-7f0922e05727"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c1580a51160>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar con checkpointing\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "ipYBiJzD0aL9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"colab_test_1\"}}\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"¿Cómo puedo optimizar el rendimiento de mi aplicación Flask?\"}\n",
        "    ],\n",
        "    \"current_step\": \"initial\",\n",
        "    \"analysis_results\": {}\n",
        "}\n",
        "\n",
        "print(\"Ejecutando agente con Gemini en LangGraph...\")\n",
        "result = app.invoke(initial_state, config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbZa8lWJ0dY1",
        "outputId": "bf172deb-dcaa-43e4-9856-e4eed2013a6a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejecutando agente con Gemini en LangGraph...\n",
            " Análisis completado: ¡Excelente pregunta! Optimizar el rendimiento de una aplicación Flask es un proceso multifacético qu...\n",
            "Respuesta generada: Optimizar el rendimiento de una aplicación Flask implica abordar varios aspectos, desde el código ha...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RESULTADO FINAL DEL AGENTE\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Paso actual: {result['current_step']}\")\n",
        "print(f\"Análisis: {result['analysis_results']}\")\n",
        "print(\"\\n RESPUESTA DEL AGENTE:\")\n",
        "print(result[\"messages\"][-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t1UY83q0eM9",
        "outputId": "8bbca92c-a07a-4652-a15f-46f1ba9842f4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RESULTADO FINAL DEL AGENTE\n",
            "==================================================\n",
            "Paso actual: response_generated\n",
            "Análisis: {'intent': 'technical_support', 'confidence': 0.92, 'details': '¡Excelente pregunta! Optimizar el rendimiento de una aplicación Flask es un proceso multifacético que abarca desde la escritura del código hasta la configuración del servidor y la base de datos. Como analista experto, te guiaré a través de las estrategias clave.\\n\\n**Principio fundamental: Mide antes de optimizar.** No adivines dónde está el cuello de botella. Usa herramientas para identificar los puntos lentos.\\n\\nAquí tienes un plan detallado para optimizar tu aplicación Flask:\\n\\n---\\n\\n### 1. Monitoreo y Profiling (¡El primer paso!)\\n\\nAntes de hacer cualquier cambio, necesitas saber *qué* está lento.\\n\\n*   **Flask-DebugToolbar:** Una excelente herramienta para desarrollo que muestra información sobre peticiones, plantillas, SQL, etc.\\n*   **`cProfile` (Python\\'s built-in profiler):** Para analizar el rendimiento de funciones específicas o partes del código. Puedes integrarlo para perfilar peticiones.\\n*   **APM (Application Performance Monitoring) Tools:**\\n    *   **Sentry:** Principalmente para monitoreo de errores, pero también puede dar métricas de rendimiento.\\n    *   **New Relic, Datadog, Prometheus/Grafana:** Soluciones más robustas para monitorear servidores, aplicaciones y bases de datos en producción.\\n*   **Logging:** Un logging adecuado (pero no excesivo) puede ayudarte a rastrear tiempos de ejecución y errores.\\n\\n---\\n\\n### 2. Optimización del Código Python y Flask\\n\\nUna vez que sepas dónde está el problema, enfócate en el código.\\n\\n*   **Base de Datos (¡El cuello de botella más común!):**\\n    *   **Problema N+1:** Evita hacer una consulta para obtener una lista de objetos y luego *otra consulta por cada objeto* para obtener sus relaciones. Usa `joinedload`, `subqueryload` o `selectinload` con SQLAlchemy.\\n    *   **Indexación:** Asegúrate de que las columnas utilizadas en `WHERE` clauses, `JOIN`s y `ORDER BY` estén indexadas.\\n    *   **Consultas Eficientes:** Recupera solo las columnas que necesitas (`session.query(User.id, User.name)` en lugar de `session.query(User)` si solo necesitas ID y nombre).\\n    *   **Connection Pooling:** Usa una librería como `SQLAlchemy` que maneja el pooling de conexiones a la base de datos de manera eficiente. Para PostgreSQL, considera `PgBouncer`.\\n    *   **Transacciones:** Envuelve múltiples operaciones de escritura en una única transacción para asegurar la consistencia y reducir el overhead.\\n*   **I/O Blocking:**\\n    *   **APIs Externas / Lectura de Archivos:** Las operaciones de entrada/salida son inherentemente lentas. Si tu aplicación realiza muchas de estas, considera:\\n        *   **Caching (ver sección 3).**\\n        *   **Asynchronous Tasks (ver sección 5).**\\n        *   **Batching:** Si es posible, agrupa múltiples llamadas a API externas en una sola solicitud.\\n*   **CPU-Bound Tasks:**\\n    *   **Procesamiento de Imágenes, Cálculos Complejos, Generación de Informes Largos:** Estas tareas bloquean el hilo principal de Flask. **Offload them** a trabajadores en segundo plano (ver sección 5).\\n    *   **Algoritmos Eficientes:** Revisa tus algoritmos. ¿Hay una forma más eficiente de lograr lo mismo?\\n*   **Serialización/Deserialización:**\\n    *   Si usas `jsonify` o librerías como `Marshmallow` o `Pydantic` para APIs REST, asegúrate de que la serialización sea eficiente. Para grandes volúmenes de datos, `ujson` puede ser más rápido que el módulo `json` estándar de Python.\\n*   **List Comprehensions y Generadores:**\\n    *   Suelen ser más rápidos y más legibles que los bucles `for` explícitos cuando se procesan colecciones. Los generadores son excelentes para grandes conjuntos de datos, ya que procesan los elementos uno a uno sin cargar todo en memoria.\\n*   **Evita Imports Largos o Costosos:**\\n    *   Si un módulo es pesado de importar y solo se necesita en funciones específicas, impórtalo localmente dentro de esa función.\\n*   **Context Processors y Decoradores:**\\n    *   Sé consciente de lo que pones en `before_request`, `after_request` o `context_processors`, ya que se ejecutan en *cada* solicitud. Asegúrate de que sean ligeros.\\n*   **Templates (Jinja2):**\\n    *   **Evita lógica compleja:** La lógica pesada debe estar en las vistas, no en las plantillas.\\n    *   **Caching:** Usa `Flask-Cache` para cachear fragmentos de plantillas o plantillas completas.\\n    *   **Reutilización:** Usa includes y extends para evitar duplicación.\\n\\n---\\n\\n### 3. Caching\\n\\nEl caching es una de las formas más efectivas de mejorar el rendimiento, ya que reduce la necesidad de recalcular o volver a consultar datos.\\n\\n*   **Caching de la Aplicación (Flask-Caching / Flask-Cache):**\\n    *   Decora tus vistas o funciones para cachear sus resultados. Ideal para datos que no cambian a menudo.\\n    *   Puedes usar Redis o Memcached como backend de caché.\\n*   **Caching de Base de Datos:**\\n    *   Cachea los resultados de consultas frecuentes que no cambian a menudo.\\n*   **Caching HTTP (Browser / Proxy):**\\n    *   Usa encabezados HTTP como `Cache-Control`, `ETag` y `Last-Modified` para permitir que los navegadores y los proxies cacheen las respuestas. Flask facilita esto con `make_response` y `set_etag`.\\n*   **CDN (Content Delivery Network):**\\n    *   Para servir archivos estáticos (CSS, JS, imágenes). Reduce la carga en tu servidor y mejora los tiempos de carga para usuarios geográficamente dispersos.\\n\\n---\\n\\n### 4. Configuración del Servidor y Despliegue\\n\\nLa forma en que despliegas tu aplicación tiene un impacto masivo en el rendimiento.\\n\\n*   **Servidor WSGI:**\\n    *   **NO uses el servidor de desarrollo de Flask en producción.** Es de un solo hilo y bloqueante.\\n    *   **Gunicorn o uWSGI:** Son los servidores WSGI recomendados para producción. Configúralos con múltiples workers y hilos para manejar la concurrencia.\\n        *   `gunicorn -w 4 -k gevent your_app:app` (4 workers, usando gevent para concurrencia no bloqueante).\\n*   **Proxy Inverso (Nginx / Apache):**\\n    *   **Sirve archivos estáticos directamente:** Configura Nginx para servir CSS, JS, imágenes, etc., sin que la solicitud llegue a Flask. Esto es crucial.\\n    *   **Terminación SSL:** Maneja HTTPS.\\n    *   **Compresión (Gzip):** Comprime las respuestas HTTP para reducir el tamaño de los datos transferidos.\\n    *   **Load Balancing:** Si tienes múltiples instancias de tu aplicación, usa Nginx para distribuir las solicitudes entre ellas.\\n*   **Recursos del Servidor:**\\n    *   Asegúrate de que tu servidor tenga suficiente CPU y RAM para manejar la carga esperada.\\n*   **Base de Datos Dedicada:**\\n    *   No ejecutes la base de datos en el mismo servidor de aplicación si el tráfico es alto. Usa un servidor de base de datos dedicado o un servicio gestionado (AWS RDS, Google Cloud SQL).\\n\\n---\\n\\n### 5. Procesamiento Asíncrono / Tareas en Segundo Plano\\n\\nPara tareas largas que no necesitan una respuesta inmediata al usuario.\\n\\n*   **Background Workers (Celery, RQ, Dramatiq):**\\n    *   Envía tareas como el envío de correos electrónicos, procesamiento de imágenes, generación de PDFs, importación/exportación de datos a una cola.\\n    *   Un \"worker\" separado (ejecutándose en un proceso diferente) consume estas tareas de la cola y las procesa, liberando al servidor Flask para que maneje nuevas solicitudes de usuarios.\\n    *   Requiere un broker de mensajes como Redis o RabbitMQ.\\n*   **WebSockets (Flask-SocketIO):**\\n    *   Para aplicaciones en tiempo real. Aunque Flask es síncrono por naturaleza (WSGI), extensiones como Flask-SocketIO pueden habilitar comunicaciones bidireccionales eficientes.\\n\\n---\\n\\n### 6. Optimización Frontend (Si aplica)\\n\\nAunque Flask es backend, la percepción del rendimiento del usuario final depende mucho del frontend.\\n\\n*   **Minificación y Compresión:**\\n    *   Minifica CSS, JavaScript y HTML.\\n    *   Usa Gzip/Brotli para comprimir activos.\\n*   **Optimización de Imágenes:**\\n    *   Comprime imágenes, usa formatos modernos (WebP).\\n    *   Carga diferida (lazy loading) para imágenes fuera de la vista inicial.\\n*   **Reducir Peticiones HTTP:**\\n    *   Combina archivos CSS y JS para reducir el número de solicitudes.\\n    *   Usa sprites CSS.\\n*   **CDN:** Para servir activos estáticos.\\n\\n---\\n\\n### Principios Generales para la Optimización\\n\\n*   **Don\\'t Optimize Prematurely:** Es el error más común. Optimiza solo cuando tengas pruebas (profiling) de que hay un problema y dónde está.\\n*   **Keep it Simple:** Un código más simple es a menudo más fácil de optimizar y depurar.\\n*   **Test Performance Regularly:** Integra pruebas de rendimiento en tu CI/CD si es posible.\\n*   **Documentación:** Registra los cambios de optimización y sus efectos.\\n\\n---\\n\\nAl aplicar estas estrategias de manera metódica, verás una mejora significativa en el rendimiento y la escalabilidad de tu aplicación Flask. ¡Mucha suerte!'}\n",
            "\n",
            " RESPUESTA DEL AGENTE:\n",
            "Optimizar el rendimiento de una aplicación Flask implica abordar varios aspectos, desde el código hasta la infraestructura. Aquí tienes una guía concisa:\n",
            "\n",
            "1.  **Configuración del Servidor Web y WSGI:**\n",
            "    *   **WSGI Server:** Usa un servidor WSGI robusto como **Gunicorn** o **uWSGI** en lugar del servidor de desarrollo de Flask.\n",
            "    *   **Reverse Proxy:** Delante del servidor WSGI, usa un proxy inverso como **Nginx** o **Apache** para manejar conexiones, servir archivos estáticos, balancear carga y aplicar compresión Gzip.\n",
            "    *   **Workers:** Configura un número adecuado de procesos/hilos worker para Gunicorn/uWSGI. Un buen punto de partida es `2 * CPU_cores + 1`.\n",
            "\n",
            "2.  **Optimización de Base de Datos:**\n",
            "    *   **Consultas Eficientes:** Optimiza tus consultas SQL. Evita N+1 queries (usa `joinedload` o `selectinload` con SQLAlchemy).\n",
            "    *   **Indexación:** Asegúrate de que las columnas utilizadas en `WHERE`, `JOIN` y `ORDER BY` tengan índices adecuados.\n",
            "    *   **Pool de Conexiones:** Utiliza un pool de conexiones (ej. con SQLAlchemy) para reducir la sobrecarga de apertura/cierre de conexiones.\n",
            "\n",
            "3.  **Caché:**\n",
            "    *   **Caché a Nivel de Aplicación:** Implementa un sistema de caché (ej. **Flask-Caching** con Redis o Memcached) para resultados de consultas costosas, respuestas de API o partes de plantillas que no cambian con frecuencia.\n",
            "    *   **Caché HTTP:** Utiliza encabezados HTTP como `Cache-Control`, `ETag` y `Last-Modified` para permitir que los navegadores y proxies almacenen en caché las respuestas.\n",
            "\n",
            "4.  **Gestión de Tareas Asíncronas:**\n",
            "    *   **Tareas en Segundo Plano:** Para operaciones que toman mucho tiempo (ej. envío de emails, procesamiento de imágenes, cálculos complejos), usa una cola de tareas como **Celery** con un broker (Redis o RabbitMQ) para ejecutarlas de forma asíncrona.\n",
            "\n",
            "5.  **Optimización del Código Flask:**\n",
            "    *   **Plantillas Jinja2:**\n",
            "        *   Usa `cache_templates=True` en `Flask(__name__, template_folder='...', static_folder='...')`.\n",
            "        *   Evita lógica compleja en las plantillas; pre-procesa los datos en tus vistas.\n",
            "        *   Usa `{% include '...' %}` para reutilizar componentes y `{% block %}` para herencia.\n",
            "    *   **Evitar Bloqueos:** Asegúrate de que tus vistas no realicen operaciones de I/O bloqueantes. Si es necesario, considera **Async/Await** con ASGI (aunque Flask es principalmente WSGI, existen adaptadores).\n",
            "    *   **Contexto de Aplicación/Petición:** Maneja los contextos de Flask de forma eficiente, liberando recursos cuando no sean necesarios.\n",
            "\n",
            "6.  **Archivos Estáticos y CDN:**\n",
            "    *   **Servicio de Estáticos:** Deja que Nginx o Apache sirvan tus archivos estáticos (`.js`, `.css`, imágenes) directamente, en lugar de que lo haga Flask.\n",
            "    *   **CDN (Content Delivery Network):** Para una escala global, considera usar una CDN para servir archivos estáticos, reduciendo la latencia para los usuarios.\n",
            "\n",
            "7.  **Monitoreo y Perfilado:**\n",
            "    *   **Perfilado:** Usa herramientas como **cProfile** (módulo estándar de Python) o **Flask-DebugToolbar** (en desarrollo) para identificar cuellos de botella en tu código.\n",
            "    *   **Monitoreo:** Integra herramientas de monitoreo (ej. Prometheus, Datadog, Sentry) para seguir métricas de rendimiento y errores en producción.\n",
            "\n",
            "8.  **Menos es Más:**\n",
            "    *   **Dependencias:** Mantén tus dependencias al mínimo. Cada librería adicional puede añadir sobrecarga.\n",
            "    *   **Logging:** Configura el logging de forma eficiente para evitar escrituras excesivas o bloqueantes.\n",
            "\n",
            "Al aplicar estas estrategias, podrás identificar y mitigar los cuellos de botella, mejorando significativamente la velocidad y la capacidad de respuesta de tu aplicación Flask.\n"
          ]
        }
      ]
    }
  ]
}